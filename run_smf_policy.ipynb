{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a6e37e",
   "metadata": {},
   "source": [
    "# Notebook to run SMF policy and SARSOP policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64777f18",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0643c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "using Distributed\n",
    "using Statistics\n",
    "using CPUTime\n",
    "using StatsBase\n",
    "using Random\n",
    "\n",
    "include(\"src/parser.jl\")\n",
    "include(\"src/simulations.jl\")\n",
    "include(\"src/models/model_MDP.jl\")\n",
    "\n",
    "Random.seed!(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f7a62",
   "metadata": {},
   "source": [
    "## Enter parameters:\n",
    "### - filename: instance name\n",
    "### - nb_sims: number of simulations\n",
    "### - Horizon: horizon time \n",
    "### - T: horizon time of the MILP\n",
    "### - T_bound: horizon time to compute the value of the upper bound $\\tilde{z}_{\\mathrm{R}^\\mathrm{c}}^{T_{bound}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf97a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the instance\n",
    "filename = \"tiger\"\n",
    "\n",
    "# parameters\n",
    "nb_sims = 100\n",
    "Horizon = 500\n",
    "T = 5\n",
    "T_bound = 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbae02",
   "metadata": {},
   "source": [
    "## Read the instance and load the parameters in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f808a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################Read the instance and load it##############################################\n",
    "S, O, A, p_init,p_emis, p_trans, reward = parser_POMDP(string(\"instances/\",filename,\".dat\"))\n",
    "\n",
    "# compute the initial belief state\n",
    "p_init = p_init./sum(p_init)\n",
    "p_trans = p_trans./sum(p_trans,dims=3)\n",
    "p_emis = p_emis./sum(p_emis,dims=3)\n",
    "\n",
    "discount=0.95\n",
    "\n",
    "\n",
    "nbS = length(S)\n",
    "nbO = length(O)\n",
    "nbA = length(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0c943",
   "metadata": {},
   "source": [
    "## Compute valid cuts probability distribution using Bayes formula\n",
    "## $p(s'|s,a,o)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba27f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cuts = zeros(length(S),length(A),length(S), length(O))\n",
    "\n",
    "for s in S, a in A, ss in S, oo in O\n",
    "    if sum(p_trans[s,a,sss]*p_emis[a,sss,oo] for sss in S) == 0\n",
    "        if ss == 1\n",
    "                p_cuts[s,a,ss,oo] = 1.0\n",
    "        else\n",
    "                p_cuts[s,a,ss,oo] = 0.0\n",
    "        end\n",
    "    else\n",
    "        p_cuts[s,a,ss,oo] = p_trans[s,a,ss]*p_emis[a,ss,oo]/sum(p_trans[s,a,sss]*p_emis[a,sss,oo] for sss in S)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e2cff",
   "metadata": {},
   "source": [
    "## Compute MDP value function as tailReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f5a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n"
     ]
    }
   ],
   "source": [
    "############################### Compute MDP value function with value #####\n",
    "tailReward = zeros(nbS)\n",
    "mdp = model_MDP(S,A,p_init,p_trans,reward,discount)\n",
    "\n",
    "optimize!(mdp)\n",
    "v_function = JuMP.value.(mdp[:v_s])\n",
    "for s in S\n",
    "        tailReward[s] = v_function[s]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee67e6",
   "metadata": {},
   "source": [
    "## Define simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3617fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = zeros(Int64, nb_sims)\n",
    "init_obs = zeros(Int64, nb_sims)\n",
    "belief_state = ones(Float64,nb_sims,nbS)\n",
    "\n",
    "# the first is drwan according to uniform distribution \n",
    "p_uniform = (1/nbS)* ones(nbS)\n",
    "\n",
    "# define the set of initial states and observations \n",
    "for sim in 1:nb_sims\n",
    "        init_state[sim] = sample(S,Weights(p_uniform))\n",
    "        init_obs[sim] = sample(O,Weights(p_emis[1,init_state[sim],:]))\n",
    "        belief_state[sim,:] = p_init\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953e4b5",
   "metadata": {},
   "source": [
    "## Compute upper bound $\\tilde{z}_{\\mathrm{R}}^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70649bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188.9999999999998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define linear relaxation\n",
    "model_lp = model_tailedMILP(T_bound,S,O,A,p_init,p_trans,p_emis,reward,tailReward,discount)\n",
    "model_lp = relax_model(model_lp)\n",
    "optimize!(model_lp)\n",
    "\n",
    "\n",
    "# get the values\n",
    "obj_lp = objective_value(model_lp)\n",
    "opt_status = termination_status(model_lp)\n",
    "obj_bound_lp = JuMP.objective_bound(model_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5624362",
   "metadata": {},
   "source": [
    "## Compute upper bound $\\tilde{z}_{\\mathrm{R}^{\\mathrm{c}}}^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea32a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n"
     ]
    }
   ],
   "source": [
    "###################### Compute upper bounds small horizon #########################\n",
    "model_lp = model_tailedMILP_cuts(T_bound,S,O,A,p_init,p_trans,p_emis,p_cuts,reward,tailReward,discount)\n",
    "model_lp = relax_model(model_lp)\n",
    "optimize!(model_lp)\n",
    "\n",
    "\n",
    "obj_lp_cuts = objective_value(model_lp_cuts)\n",
    "opt_cuts_status = termination_status(model_lp_cuts)\n",
    "\n",
    "if opt_cuts_status== \"TIME_LIMIT\"\n",
    "        obj_lp_cuts = JuMP.objective_bound(model_lp_cuts)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516e192",
   "metadata": {},
   "source": [
    "## Compute SARSOP policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "722619cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== POMDP policies on discounted infinite horizon =======\n",
      "Generating a pomdpx file: tiger.pomdpx\n",
      "\n",
      "Loading the model ...\n",
      "  input file   : tiger.pomdpx\n",
      "  loading time : 0.00s \n",
      "\n",
      "SARSOP initializing ...\n",
      "  initialization time : 0.00s\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      " Time   |#Trial |#Backup |LBound    |UBound    |Precision  |#Alphas |#Beliefs  \n",
      "-------------------------------------------------------------------------------\n",
      " 0       0       0        -20        92.8206    112.821     3        1        \n",
      " 0.01    2       51       -6.2981    63.1396    69.4377     7        16       \n",
      " 0.01    4       103      0.149651   52.2764    52.1268     9        21       \n",
      " 0.01    6       151      6.19248    42.0546    35.8621     9        21       \n",
      " 0.01    8       200      10.3563    35.232     24.8757     12       21       \n",
      " 0.01    11      250      14.0433    29.5471    15.5037     6        21       \n",
      " 0.01    14      300      16.545     25.0926    8.54759     10       21       \n",
      " 0.01    17      350      18.2281    21.8163    3.5882      14       21       \n",
      " 0.01    18      400      18.7451    20.9384    2.19328     8        21       \n",
      " 0.01    21      465      19.1109    20.0218    0.910956    5        21       \n",
      " 0.01    22      500      19.2369    19.7071    0.470219    11       21       \n",
      " 0.01    24      550      19.3036    19.5405    0.236865    6        21       \n",
      " 0.01    25      600      19.3369    19.4574    0.120445    13       21       \n",
      " 0.01    27      669      19.3579    19.4049    0.0469305   5        21       \n",
      " 0.01    28      713      19.3643    19.389     0.024739    5        21       \n",
      " 0.01    29      757      19.3676    19.3807    0.0130409   5        21       \n",
      " 0.01    30      801      19.3694    19.3763    0.0068744   5        21       \n",
      " 0.01    31      850      19.3704    19.3739    0.00351433  10       21       \n",
      " 0.01    32      900      19.3709    19.3725    0.00155165  5        21       \n",
      " 0.01    33      936      19.3711    19.3721    0.000976551 8        21       \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "SARSOP finishing ...\n",
      "  target precision reached\n",
      "  target precision  : 0.001000\n",
      "  precision reached : 0.000977 \n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      " Time   |#Trial |#Backup |LBound    |UBound    |Precision  |#Alphas |#Beliefs  \n",
      "-------------------------------------------------------------------------------\n",
      " 0.01    33      936      19.3711    19.3721    0.000976551 5        21       \n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Writing out policy ...\n",
      "  output file : tiger_policy.out\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0388028621673584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "@printf \"=============== POMDP policies on discounted infinite horizon =======\\n\"\n",
    "pomdp = def_pomdp(S,O,A,p_init,p_emis,p_trans,reward,discount)\n",
    "start = time()\n",
    "SARSOPpolicy = compute_policy(filename,pomdp)\n",
    "SARSOP_time = time()-start\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d6ed9",
   "metadata": {},
   "source": [
    "## Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4499465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Start simulation 1 ============================\n",
      "=============Run SMF policy T=5 ================== \n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "=============Run SARSOP policy ================== \n",
      "================Start simulation 2 ============================\n",
      "=============Run SMF policy T=5 ================== \n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-10\n",
      "Set parameter TimeLimit to value 3600\n",
      "Set parameter MIPGap to value 0.001\n",
      "=============Run SARSOP policy ================== \n"
     ]
    }
   ],
   "source": [
    "# Rewards of SMF policy\n",
    "SMF_reward = zeros(nb_sims)\n",
    "SMF_time = zeros(nb_sims)\n",
    "\n",
    "# Reward of SARSOP policy\n",
    "SARSOP_reward = zeros(nb_sims)\n",
    "SARSOP_time = SARSOP_time/nb_sims\n",
    "\n",
    "for sim in 1:nb_sims\n",
    "    @printf \"================Start simulation %.0f ============================\\n\" sim\n",
    "\n",
    "    ###########################################################\n",
    "\n",
    "    Random.seed!(sim)\n",
    "    @printf \"=============Run SMF policy T=%.0f ================== \\n\" T\n",
    "    ######## Run SMF policy ########\n",
    "    policy_reward, policy_time = simulation(\"SMF\",SARSOPpolicy,Horizon,T,S,O,A,p_init,p_emis,p_trans,reward,tailReward,discount,init_state[sim],init_obs[sim])\n",
    "    SMF_reward[sim] = policy_reward\n",
    "    SMF_time[sim] = policy_time\n",
    "    #####################################################\n",
    "\n",
    "    Random.seed!(sim)\n",
    "    @printf \"=============Run SARSOP policy ================== \\n\"\n",
    "    \n",
    "    ########Run MILP heuristic with cuts########\n",
    "    policy_reward, policy_time = simulation(\"SARSOP\",SARSOPpolicy,Horizon,T,S,O,A,p_init,p_emis,p_trans,reward,tailReward,discount,init_state[sim],init_obs[sim])\n",
    "    SARSOP_reward[sim] = policy_reward\n",
    "    #####################################################\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67503a66",
   "metadata": {},
   "source": [
    "## Compute the optimality gap $G^{T_{bound}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82833cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 91.84023005847688\n",
       " 86.12216627272713"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bound = [min(obj_lp_cuts,obj_lp) for i in 1:nb_sims]\n",
    "\n",
    "# compute gaps on larger horizon (smaller gaps)\n",
    "SMF_gap = 100*(best_bound - SMF_reward)./abs.(best_bound)\n",
    "SARSOP_gap = 100*(best_bound - SARSOP_reward)./abs.(best_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bc9b1",
   "metadata": {},
   "source": [
    "## Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c34c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "===================================================================\n",
      "===========================================================\n",
      "==============================================\n",
      "============= Results ==================\n",
      "Upper bound with inequalities (11) and T=T_bound : 127.624053 \n",
      "Upper bound with T=T_bound : 189.000000 \n",
      "\n",
      "===== SMF policy T=5 =====\n",
      "SMF policy gap with T_bound : 96.542605 \n",
      "SMF policy reward : 4.412468 \n",
      "SMF policy time : 0.041419 \n",
      "\n",
      "===== SARSOP policy T=5 =====\n",
      "SARSOP policy gap with T_bound : 88.981198 \n",
      "SARSOP policy reward : 14.062641 \n",
      "SARSOP policy time : 0.019401 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "@printf \"============================================================================\\n\"\n",
    "@printf \"===================================================================\\n\"\n",
    "@printf \"===========================================================\\n\"\n",
    "@printf \"==============================================\\n\"\n",
    "@printf \"============= Results ==================\\n\"\n",
    "\n",
    "@printf \"Upper bound with inequalities (11) and T=T_bound : %f \\n\" obj_lp_cuts\n",
    "@printf \"Upper bound with T=T_bound : %f \\n\\n\" obj_lp\n",
    "\n",
    "@printf \"===== SMF policy T=%.0f =====\\n\" T\n",
    "@printf \"SMF policy gap with T_bound : %f \\n\" mean(SMF_gap)\n",
    "@printf \"SMF policy reward : %f \\n\" mean(SMF_reward)\n",
    "@printf \"SMF policy time : %f \\n\\n\" mean(SMF_time)\n",
    "\n",
    "@printf \"===== SARSOP policy T=%.0f =====\\n\" T\n",
    "@printf \"SARSOP policy gap with T_bound : %f \\n\" mean(SARSOP_gap)\n",
    "@printf \"SARSOP policy reward : %f \\n\" mean(SARSOP_reward)\n",
    "@printf \"SARSOP policy time : %f \\n\\n\" SARSOP_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
